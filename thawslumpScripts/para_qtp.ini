#the parameter file for Image Segmentation and Object Image analysis

##############################################################
###input and output setting

# the upper level of the folder where you running scripts, for example,
# you running in folder: /home/hlc/Data/Qinghai-Tibet/entire_QTP_images/sentinel-2/autoMapping/BLH_deeplabV3+_1
working_root=/home/hlc/Data/Qinghai-Tibet/entire_QTP_images/sentinel-2/autoMapping

#
input_image_dir = /home/hlc/Data/Qinghai-Tibet/entire_QTP_images/sentinel-2/8bit_dir/sentinel-2_2018_mosaic_v4_Albers


# image segment scale, script will resample the original to this resolution (meter)
input_image_rescale = 10.0
# training_polygons includes all the training polygons (ground truth and non-ground truth)
training_polygons= /home/hlc/Data/Qinghai-Tibet/qtp_thaw_slumps/rts_polygons_s2_2018/qtp_train_polygons_s2_2018_v2_Albers.shp
# training_polygons_sub for getting the image subset. (equal to or a portion of the all training polygons)
training_polygons_sub = /home/hlc/Data/Qinghai-Tibet/qtp_thaw_slumps/rts_polygons_s2_2018/qtp_train_polygons_s2_2018_v2_Albers.shp

# a text file store multi training polyons and the corresponding images,
# if this value is set, training_polygons, and training_polygons_sub will be ignored
# the format for each line is "image_folder:image_pattern:polyogn_path", e.g., "201907:*new_warp.tif:traing_polygons.shp"
multi_training_files = multi_training_files.txt

# the sub images for traing (relative path in the current folder)
input_train_dir= subImages
# the sub label images for training (relative path in the current folder)
input_label_dir= subLabels

# the folder containing images for inference
inf_images_dir = /home/hlc/Data/Qinghai-Tibet/entire_QTP_images/sentinel-2/8bit_dir/sentinel-2_2018_mosaic_v4_Albers

## the following for calcuating topography and hydrology information,
## if don't have the file, leave the value as nothing instead remove (or comment)
dem_file = /home/hlc/Data/Qinghai-Tibet/qtp_dem/qtp_srtm_v3_30m_crop.tif

slope_file = /home/hlc/Data/Qinghai-Tibet/qtp_dem/dem_derived/qtp_srtm_v3_30m_crop_sagaSlope.tif

aspect_file = /home/hlc/Data/Qinghai-Tibet/qtp_dem/dem_derived/qtp_srtm_v3_30m_crop_sagaAspect.tif

flow_accumulation =

# define the Cartesian (XY) projection
# the following projection (wkt string) came from ran.shp (gdalsrsinfo -o wkt ran.shp), the Permafrost map on the Tibetan Plateau
# need to modify it if switch to other regions
cartensian_prj = PROJCS["Krasovsky_1940_Albers",GEOGCS["GCS_WGS_1984",DATUM["WGS_1984",SPHEROID["WGS_84",6378137.0,298.257223563]],PRIMEM["Greenwich",0.0],UNIT["Degree",0.0174532925199433]],PROJECTION["Albers_Conic_Equal_Area"],PARAMETER["False_Easting",0.0],PARAMETER["False_Northing",0.0],PARAMETER["longitude_of_center",90.0],PARAMETER["Standard_Parallel_1",27.5],PARAMETER["Standard_Parallel_2",37.5],PARAMETER["latitude_of_center",0.0],UNIT["Meter",1.0]]

###end input and output setting
##############################################################


##############################################################
## taining parameter
batch_size=8
# experiment name
expr_name=exp1
# the number of iteration
iteration_num=30000

# data augmentaion
data_augmentation = flip, rotate, blur, crop, scale
# ignore class when perform data augmentation, multiple class will be support in future
data_aug_ignore_classes=class_0

# class number (without background)
NUM_CLASSES_noBG = 1

#base_learning_rate
# Use 0.007 when training on PASCAL augmented training set, train_aug. When
# fine-tuning on PASCAL trainval set, use learning rate=0.0001. (from deeplab train.py)
base_learning_rate=0.007

# For `xception_65`, use atrous_rates = [12, 24, 36] if output_stride = 8, or
# rates = [6, 12, 18] if output_stride = 16. Note one could use different
# atrous_rates/output_stride during training/evaluation. (from deeplab train.py)
output_stride=16
atrous_rates1=6
atrous_rates2=12
atrous_rates3=18

# 1 for export multi scale frozen inference graph, 0 for single-scale
export_multi_scale = 1
# which saved snapshot will be exported to the frozen graph, can be equal to less than iteration_num
export_iteration_num=30000
# batch size for inference
inf_batch_size=1

##############################################################


##############################################################
###pre-processing parameters
#buffer size for extending the training polygon, in the projection, normally, it is based on meters
buffer_size = 300

#whether use the rectangular extent of the polygon, set "--rectangle" on right if Yes, or omit it if NO
b_use_rectangle = --rectangle

#the nodata in output images, for sentinel, set dst_nodata as 0
dst_nodata = 0

# image format for spliting images: .tif or .png
split_image_format = .png
## patch width and height of training images (eg. 480=160+160*2)
train_patch_width = 160
train_patch_height = 160
train_pixel_overlay_x = 160
train_pixel_overlay_y = 160

## patch with, height, and pixel_overlay of inference images (eg. )
#  480=352+2*64 (width)
#  480=352+2*64 (height)
# the expected width of patch (70)
inf_patch_width= 160
# the expected height of patch (70)
inf_patch_height=160
# the overlay of patch in pixel (210)
inf_pixel_overlay_x=160
inf_pixel_overlay_y=160


## patch width and height of network (such as U-net)
#out_patch_width=480
#out_patch_height=480

###end pre-processing parameters
##############################################################


##############################################################
### Post processing and evaluation Parameters

# the minimum area of gully or other landforms, if any polygon small than minimum_area, it will be removed
minimum_area = 100

# assuming ratio=height/width (suppose height > width), ratio belong to [0,1], if any polygon has ratio greater than
#                     maximum_ratio_width_height, it will be removed
maximum_ratio_width_height = 1.0

# the more narrow, the ratio (=perimeter^2/area) is larger
minimum_ratio_perimeter_area = 0

# the minimum mean elevation in meters (if dem_mean of a polyogn small than this value, it will be removed)
minimum_elevation = 3000

# indicate whether use the surrounding buffer area to calcuate the topography information, if NO, it counts the pixels inside a polygon
b_topo_use_buffer_area = Yes

# keep holes
b_keep_holes=YES

# validation files for evaluation
validation_shape =

IOU_threshold = 0.5

#end Post processing and evaluation Parameters
##############################################################

##############################################################
### QGIS Parameters Setting linux: /usr    mac: /Applications/QGIS.app/Contents/MacOS

#end QGIS Parameters Setting
##############################################################
